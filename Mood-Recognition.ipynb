{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib as plt\n",
    "import time, csv, os, shutil, sys\n",
    "\n",
    "# Data preparation\n",
    "\n",
    "j=0\n",
    "label=0\n",
    "trainPath = \"../Mood_Detector/training.csv\"\n",
    "dstPath = \"../Mood_Detector/\"\n",
    "imgPath = \"../Mood_Detector/Manually_Annotated/Manually_Annotated_Images/\"\n",
    "\n",
    "with open(trainPath, 'r') as trainFile:\n",
    "    sp = []\n",
    "    skip_to_line = 0\n",
    "    for lines in trainFile:\n",
    "        skip_to_line += 1\n",
    "        # skip header\n",
    "        if skip_to_line == 1:\n",
    "            for lines in trainFile:\n",
    "                sp = lines.split(',')\n",
    "                # get the label\n",
    "                label = sp[6]\n",
    "                # move the image file path into corresponding target directory\n",
    "                shutil.move(imgPath+sp[0],dstPath + label + \"/\")\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib as plt\n",
    "import time, csv, os, shutil, sys\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "trainPath = \"../Mood_Detector/training.csv\"\n",
    "dstPath = \"../Mood_Detector/\"\n",
    "imgPath = \"../Mood_Detector/Manually_Annotated/Manually_Annotated_Images/\"\n",
    "\n",
    "CATEGORIES = [\"Neutral\",\"Happiness\",\"Sadness\",\"Surprise\",\"Fear\",\"Disgust\",\"Anger\",\"Contempt\"]\n",
    "training_data = []\n",
    "IMG_SIZE = 64\n",
    "i=0\n",
    "\n",
    "# data preparation and converting BGR images to RGB. \n",
    "def createTrainData():    \n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(dstPath, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))\n",
    "                img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "                new_array = cv2.resize(img_array,(IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "\n",
    "createTrainData()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "# shuffle the data\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, labels in training_data:\n",
    "    X.append(features)\n",
    "    y.append(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# we pickle the data for safe keeping \n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# we Load the data set and we reshape the data.\n",
    "IMG_SIZE = 64\n",
    "\n",
    "X = pickle.load(open(\"../GPA_759/Data_Set/X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"../GPA_759/Data_Set/y.pickle\",\"rb\"))\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "\n",
    "# I convert and normalize half the data, because my RAM can't take it all...\n",
    "# batch_num = 1\n",
    "batch_num = 2\n",
    "\n",
    "def getHalfData(data, batch_num):\n",
    "    if batch_num == 1:\n",
    "        d = data[:int(len(data)/2)]\n",
    "    elif batch_num == 2 :\n",
    "        d = data[int(len(data)/2)+1:]\n",
    "\n",
    "    return d\n",
    "\n",
    "# i'm Normalizing half the data\n",
    "def dataNormalization(data, batch_num):\n",
    "    if batch_num == 1:\n",
    "        d = data[:int(len(data)/2),:,:,:].astype('float32')\n",
    "        d /= 255\n",
    "    elif batch_num == 2 :\n",
    "        d = data[int(len(data)/2)+1:,:,:,:].astype('float32')\n",
    "        d /= 255\n",
    "\n",
    "    return d\n",
    "    \n",
    "x_train = dataNormalization(x_train, batch_num)\n",
    "x_test = dataNormalization(x_test, batch_num)\n",
    "y_train = getHalfData(y_train, batch_num)\n",
    "y_test = getHalfData(y_test, batch_num)\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "# print(y_train)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Activation, MaxPooling2D, BatchNormalization, GlobalMaxPooling2D, Dropout, Flatten\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "# num_classes = 10\n",
    "num_classes = 8\n",
    "num_epochs = 40\n",
    "num_batch = 32\n",
    "\n",
    "# # train data and test data for cifar10 dataset\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# print(x_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "# input : 64, 64 color RGB\n",
    "# conv1\n",
    "model.add(Conv2D(66, (3,3), padding='same', input_shape=x_train.shape[1:])) # change input shape\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001, scale=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Conv 2, 3 and 4\n",
    "model.add(Conv2D(128,(3,3),padding='same'))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001, scale=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128,(3,3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001, scale=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128,(3,3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001, scale=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Conv 5\n",
    "model.add(Conv2D(192, (3,3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001, scale=True))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Conv 6, 7, 8 and 9\n",
    "model.add(Conv2D(192,(3,3),padding='same'))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001, scale=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(192,(3,3),padding='same'))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001, scale=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(192,(3,3),padding='same'))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001, scale=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(192,(3,3),padding='same'))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001, scale=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Conv 9\n",
    "model.add(Conv2D(288, (3,3), padding='same'))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001, scale=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Conv 10\n",
    "model.add(Conv2D(288, (3,3), padding='same'))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001, scale=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Conv 11\n",
    "model.add(Conv2D(355, (3,3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001, scale=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Conv 12\n",
    "model.add(Conv2D(432, (3,3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001, scale=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "\n",
    "# fully connected Layer MLP \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax', bias_initializer='constant'))\n",
    "\n",
    "\n",
    "# Initialise the optimizer Adam \n",
    "#optim = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "optim = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "\n",
    "\n",
    "# Compile the model \n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=optim, metrics = ['accuracy'])\n",
    "\n",
    "# If we are using data augmentation then we augment the images\n",
    "#horizontal/vertical flip and random rotation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "# apply the transformation on the train images\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# we want to reduce the LR once we hit a plateau \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Fit the model with the dataset and start training\n",
    "model.fit(x_train, y_train, batch_size=num_batch, epochs=num_epochs, callbacks=[reduce_lr], validation_split=0.2, shuffle=True )\n",
    "\n",
    "# Then we evaluate the model with evaluate()\n",
    "# and we print the models score\n",
    "score = model.evaluate(x_test, y_test, batch_size=num_batch)\n",
    "print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"MoodSimpNetV2-1DenseLayer-Softmax40.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "\n",
    "nameList = []\n",
    "CATEGORIES = [\"Neutral\",\"Happiness\",\"Sadness\",\"Surprise\",\"Fear\",\"Disgust\",\"Anger\",\"Contempt\"]\n",
    "\n",
    "IMG_SIZE = 64\n",
    "unl = 1\n",
    "\n",
    "if unl == 1:\n",
    "    # Load the pre-trained model only once\n",
    "    model = load_model('../GPA_759/Pretrained_network/MoodSimpNetV2-1DenseLayer-Softmax40-v2.h5')\n",
    "\n",
    "# Get a reference to webcam #0\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while (video_capture.isOpened()):\n",
    "    \n",
    "    #get a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    if ret:\n",
    "\n",
    "        # resizing the frame for faster face recognition processing\n",
    "        faceFrame  = cv2.resize(frame, (0,0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # we take the face location(s) in the image \n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "\n",
    "        # Notes: instead of saving the images we could \n",
    "        # pass the image straight to the CNN for classification\n",
    "\n",
    "        for face_location in face_locations:\n",
    "\n",
    "            # carré 129 par 129\n",
    "            top, right, bottom, left = face_location\n",
    "            cropped_roi = frame[top-70:bottom+20,left-50:right+50]\n",
    "            new_array = cv2.resize(cropped_roi,(IMG_SIZE, IMG_SIZE))\n",
    "            new_array = cv2.cvtColor(new_array, cv2.COLOR_BGR2RGB)\n",
    "            new_array = new_array[np.newaxis,:,:,:]\n",
    "            new_array = new_array.astype('float32')\n",
    "            new_array /= 255\n",
    "            \n",
    "            \n",
    "            # we then classify the image and print the result\n",
    "            moodPrediction = model.predict(new_array)\n",
    "\n",
    "            # we draw rectangles around the faces\n",
    "            cv2.rectangle(frame,(left-50,top-70), (right+50, bottom+20), (0,0,255), 2)\n",
    "            # we draw the labels with the names over, or below the face\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, CATEGORIES[np.argmax(moodPrediction)], (left -50, bottom ), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        # we Display the image\n",
    "        cv2.imshow('Video',frame)\n",
    "\n",
    "        # Hit 'q' on the keyboard to quit!\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Release handle to the webcam\n",
    "unl = 0\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Activation, MaxPooling2D, BatchNormalization, GlobalMaxPooling2D, Dropout, Flatten\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, TensorBoard\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "# Here we load the model to be able to train it with another set of images.\n",
    "\n",
    "model = load_model('../GPA_759/Pretrained_network/MoodSimpNetV2-1DenseLayer-Softmax40-v2.h5')\n",
    "\n",
    "# num_classes = 10\n",
    "num_classes = 8\n",
    "num_epochs = 40\n",
    "num_batch = 32\n",
    "\n",
    "# # train data and test data for cifar10 dataset\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# print(x_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "# Initialise the optimizer Adam \n",
    "#optim = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "optim = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "\n",
    "\n",
    "# Compile the model \n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=optim, metrics = ['accuracy'])\n",
    "\n",
    "# If we are using data augmentation then we augment the images\n",
    "#horizontal/vertical flip and random rotation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "# apply the transformation on the train images\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# we want to reduce the LR once we hit a plateau \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Fit the model \n",
    "model.fit(x_train, y_train, batch_size=num_batch, epochs=num_epochs, callbacks=[reduce_lr], validation_split=0.2, shuffle=True )\n",
    "\n",
    "# Then we evaluate the model with evaluate()\n",
    "# and we print the model\n",
    "score = model.evaluate(x_test, y_test, batch_size=num_batch)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../GPA_759/Pretrained_network/MoodSimpNetV2-1DenseLayer-Softmax40-v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
